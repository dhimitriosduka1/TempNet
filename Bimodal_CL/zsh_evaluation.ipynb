{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6570bb3",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c21453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BS/dduka/work/micromamba/envs/bimodal_cl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from models.model_clip import CLIP\n",
    "from dataset.caption_dataset import imagenet_templates\n",
    "from transformers import AutoTokenizer, RobertaTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed3b06",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871735aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a35cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def zeroshot_transfer(model, data_loader, dataset_name, tokenizer, device):\n",
    "    model.eval()\n",
    "\n",
    "    if dataset_name == \"imagenet\":\n",
    "        classes = [cls[0] for cls in data_loader.dataset.classes]\n",
    "        templates = imagenet_templates\n",
    "    else:\n",
    "        print(f\"===> Loading zeroshot transfer config for {dataset_name}\")\n",
    "        config = eval(open(f\"zeroshot_transfer/{dataset_name}_classes.py\", \"r\").read())\n",
    "        classes, templates = config[\"classes\"], config[\"templates\"]\n",
    "\n",
    "    text_embeddings = []\n",
    "    for c in classes:  # Classes here are the string names of the classes\n",
    "        texts = [template.format(c) for template in templates]\n",
    "        text_inputs = tokenizer(\n",
    "            texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=30,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(device)\n",
    "        text_outputs = model.text_encoder(\n",
    "            text_inputs.input_ids,\n",
    "            attention_mask=text_inputs.attention_mask,\n",
    "            output_hidden_states=False,\n",
    "        )\n",
    "        text_embeds = F.normalize(\n",
    "            model.text_proj(text_outputs.last_hidden_state[:, 0, :]), dim=-1\n",
    "        )\n",
    "        text_embed = text_embeds.mean(dim=0)\n",
    "        text_embed /= text_embed.norm()\n",
    "        text_embeddings.append(text_embed)\n",
    "\n",
    "    text_embeddings = torch.stack(text_embeddings, dim=1).to(device)\n",
    "\n",
    "    topk = [1, 3, 5, 10]\n",
    "    correct = {k: 0 for k in topk}\n",
    "\n",
    "    for image, label in tqdm(data_loader, desc=\"Evaluating zeroshot transfer\"):\n",
    "        image, label = image.to(device), label.to(\n",
    "            device\n",
    "        )  # label is the index (number) of the class\n",
    "        image_feat = model.visual_encoder(image)\n",
    "        image_embed = model.vision_proj(image_feat)\n",
    "        image_embedding = F.normalize(image_embed, dim=-1)\n",
    "\n",
    "        logits = image_embedding @ text_embeddings\n",
    "        ranks = logits.topk(max(topk), 1)[1].T\n",
    "        predictions = ranks == label\n",
    "\n",
    "        for k in topk:\n",
    "            correct[k] += torch.sum(torch.any(predictions[:k], dim=0)).item()\n",
    "\n",
    "    results = {f\"zeroshot_top{k}\": correct[k] / data_loader.num_samples for k in topk}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b247208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zeroshot_dataloader(dataset_name, data_folder, image_size, train=False):\n",
    "    if dataset_name == \"cifar10\":\n",
    "        mean = (0.4914, 0.4822, 0.4465)\n",
    "        std = (0.2023, 0.1994, 0.2010)\n",
    "    elif dataset_name == \"cifar100\":\n",
    "        mean = (0.5071, 0.4867, 0.4408)\n",
    "        std = (0.2675, 0.2565, 0.2761)\n",
    "    elif dataset_name == \"mnist\":\n",
    "        mean = (0.1307, 0.1307, 0.1307)\n",
    "        std = (0.3081, 0.3081, 0.3081)\n",
    "    else:\n",
    "        # For the following datasets:\n",
    "        # imagenet, food101, flowers102, sun397, fgvc-aircraft\n",
    "        mean = (0.485, 0.456, 0.406)\n",
    "        std = (0.229, 0.224, 0.225)\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    val_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.Grayscale(num_output_channels=3) if dataset_name == \"mnist\" else transforms.Lambda(lambda x: x),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if dataset_name == \"cifar10\":\n",
    "        dataset = datasets.CIFAR10(\n",
    "            root=data_folder, \n",
    "            download=False, \n",
    "            train=train, \n",
    "            transform=val_transform\n",
    "        )\n",
    "        print(f\"CIFAR10 classes: {dataset.class_to_idx}\")\n",
    "    elif dataset_name == \"cifar100\":\n",
    "        dataset = datasets.CIFAR100(\n",
    "            root=data_folder, \n",
    "            download=False, \n",
    "            train=train, \n",
    "            transform=val_transform\n",
    "        )\n",
    "        print(f\"CIFAR100 classes: {dataset.class_to_idx}\")\n",
    "    elif dataset_name == \"imagenet\":\n",
    "        dataset = datasets.ImageNet(\n",
    "            root=\"/BS/dduka/work/data/imagenet1k/\",\n",
    "            split=\"val\",\n",
    "            transform=val_transform,\n",
    "        )\n",
    "        print(f\"ImageNet classes: {dataset.class_to_idx}\")\n",
    "    elif dataset_name == \"mnist\":\n",
    "        dataset = datasets.MNIST(\n",
    "            root=data_folder, \n",
    "            download=False, \n",
    "            train=False, \n",
    "            transform=val_transform\n",
    "        )\n",
    "        print(f\"MNIST classes: {dataset.class_to_idx}\")\n",
    "    elif dataset_name == \"sun397\":\n",
    "        dataset = datasets.SUN397(\n",
    "            root=\"/BS/databases03\",\n",
    "            transform=val_transform\n",
    "        )\n",
    "        print(f\"SUN397 classes: {dataset.class_to_idx}\")\n",
    "    elif dataset_name == \"fgvc-aircraft\":\n",
    "        dataset = datasets.FGVCAircraft(\n",
    "            root=\"/scratch/inf0/user/dduka\",\n",
    "            split=\"test\",\n",
    "            download=True,\n",
    "            transform=val_transform,\n",
    "        )\n",
    "        print(f\"FGVC-Aircraft classes: {dataset.class_to_idx}\")\n",
    "    elif dataset_name == \"oxford-pets\":\n",
    "        dataset = datasets.OxfordIIITPet(\n",
    "            root=\"/scratch/inf0/user/dduka\", \n",
    "            download=True, \n",
    "            transform=val_transform,\n",
    "            split=\"test\"\n",
    "        )\n",
    "        print(f\"Oxford-IIIT Pet classes: {dataset.class_to_idx}\")\n",
    "    elif dataset_name == \"flowers102\":\n",
    "        dataset = datasets.Flowers102(\n",
    "            root=\"/scratch/inf0/user/dduka\", \n",
    "            download=True, \n",
    "            split=\"test\", \n",
    "            transform=val_transform\n",
    "        )\n",
    "    elif dataset_name == \"eurosat\":\n",
    "        dataset = datasets.EuroSAT(\n",
    "            root=\"/scratch/inf0/user/dduka\", \n",
    "            download=True, \n",
    "            transform=val_transform,\n",
    "        )\n",
    "        print(f\"EuroSAT classes: {dataset.class_to_idx}\")\n",
    "    else:\n",
    "        dataset = datasets.ImageFolder(root=data_folder, transform=val_transform)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=256, shuffle=False, num_workers=8, pin_memory=True\n",
    "    )\n",
    "\n",
    "    data_loader.num_samples = len(dataset)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c2365",
   "metadata": {},
   "source": [
    "# RN50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "675982ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn50_args = {\n",
    "    \"image_encoder\": \"resnet50\",\n",
    "    \"text_encoder\": \"distilbert-base-uncased\",\n",
    "    \"embed_dim\": 256,\n",
    "    \"init_model\": True,\n",
    "    \"world_size\": 1,\n",
    "    \"ita_type\": \"clip\",\n",
    "    \"sogclr_gamma\": 0.8,\n",
    "    \"rho\": 8.0,\n",
    "    \"tau_init\": 0.01,\n",
    "    \"temp\": 0.01,\n",
    "    \"learnable_temp\": False,\n",
    "    \"personalized_tau\": False,\n",
    "    \"vicreg_sim_coeff\": 25.0,\n",
    "    \"vicreg_std_coeff\": 25.0,\n",
    "    \"N\": -1, # don't care about this\n",
    "    \"proto_num\": 256,\n",
    "    \"proto_std\": 10.0,\n",
    "    \"upper_rho_plus\": 0.0,\n",
    "    \"proto_weight\": 1.0,\n",
    "    \"sinkhorn_eps\": 0.05,\n",
    "    \"swav_temp\": 0.1,\n",
    "    \"swav_weight\": 1.0,\n",
    "    \"total_steps\": -1, # don't care about this\n",
    "    \"sim_based_loss_alpha\": 0.1,\n",
    "    \"sim_blend_ratio\": 0.0,\n",
    "    \"clip_scheduled_loss_type\": \"none\",\n",
    "    \"use_per_sample_temp\": False,\n",
    "    \"include_unimodal_loss\": False,\n",
    "    \"disable_temo_modulation\": False,\n",
    "    \"disable_crossmodal_minfonce\": False,\n",
    "    \"disable_i2i_temo_loss\": False,\n",
    "    \"disable_t2t_temo_loss\": False,\n",
    "    \"reversed_scheduler\": False,\n",
    "    \"enable_non_modulated_unimodal_losses\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3bf6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    local_files_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b866e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_args = rn50_args.copy()\n",
    "vit_args[\"image_encoder\"] = \"vit_base_patch16_224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e24ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP(\n",
      "  (visual_encoder): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (text_encoder): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (text_proj): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (vision_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (criterion): CLIP_Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rn50_model = CLIP(\n",
    "    **rn50_args\n",
    ").to(\"cuda\")\n",
    "print(rn50_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29bcf524",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn50_checkpoint_paths = [\n",
    "    \"/BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_tau_0.01_lr_8e-4/checkpoint_best.pth\",\n",
    "    \"/BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_cos_0.01_0.05_lr_8e-4/checkpoint_best.pth\",\n",
    "    \"/BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented/checkpoint_best.pth\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "555b4a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 classes: {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "CIFAR100 classes: {'apple': 0, 'aquarium_fish': 1, 'baby': 2, 'bear': 3, 'beaver': 4, 'bed': 5, 'bee': 6, 'beetle': 7, 'bicycle': 8, 'bottle': 9, 'bowl': 10, 'boy': 11, 'bridge': 12, 'bus': 13, 'butterfly': 14, 'camel': 15, 'can': 16, 'castle': 17, 'caterpillar': 18, 'cattle': 19, 'chair': 20, 'chimpanzee': 21, 'clock': 22, 'cloud': 23, 'cockroach': 24, 'couch': 25, 'crab': 26, 'crocodile': 27, 'cup': 28, 'dinosaur': 29, 'dolphin': 30, 'elephant': 31, 'flatfish': 32, 'forest': 33, 'fox': 34, 'girl': 35, 'hamster': 36, 'house': 37, 'kangaroo': 38, 'keyboard': 39, 'lamp': 40, 'lawn_mower': 41, 'leopard': 42, 'lion': 43, 'lizard': 44, 'lobster': 45, 'man': 46, 'maple_tree': 47, 'motorcycle': 48, 'mountain': 49, 'mouse': 50, 'mushroom': 51, 'oak_tree': 52, 'orange': 53, 'orchid': 54, 'otter': 55, 'palm_tree': 56, 'pear': 57, 'pickup_truck': 58, 'pine_tree': 59, 'plain': 60, 'plate': 61, 'poppy': 62, 'porcupine': 63, 'possum': 64, 'rabbit': 65, 'raccoon': 66, 'ray': 67, 'road': 68, 'rocket': 69, 'rose': 70, 'sea': 71, 'seal': 72, 'shark': 73, 'shrew': 74, 'skunk': 75, 'skyscraper': 76, 'snail': 77, 'snake': 78, 'spider': 79, 'squirrel': 80, 'streetcar': 81, 'sunflower': 82, 'sweet_pepper': 83, 'table': 84, 'tank': 85, 'telephone': 86, 'television': 87, 'tiger': 88, 'tractor': 89, 'train': 90, 'trout': 91, 'tulip': 92, 'turtle': 93, 'wardrobe': 94, 'whale': 95, 'willow_tree': 96, 'wolf': 97, 'woman': 98, 'worm': 99}\n",
      "MNIST classes: {'0 - zero': 0, '1 - one': 1, '2 - two': 2, '3 - three': 3, '4 - four': 4, '5 - five': 5, '6 - six': 6, '7 - seven': 7, '8 - eight': 8, '9 - nine': 9}\n",
      "SUN397 classes: {'abbey': 0, 'airplane_cabin': 1, 'airport_terminal': 2, 'alley': 3, 'amphitheater': 4, 'amusement_arcade': 5, 'amusement_park': 6, 'anechoic_chamber': 7, 'apartment_building/outdoor': 8, 'apse/indoor': 9, 'aquarium': 10, 'aqueduct': 11, 'arch': 12, 'archive': 13, 'arrival_gate/outdoor': 14, 'art_gallery': 15, 'art_school': 16, 'art_studio': 17, 'assembly_line': 18, 'athletic_field/outdoor': 19, 'atrium/public': 20, 'attic': 21, 'auditorium': 22, 'auto_factory': 23, 'badlands': 24, 'badminton_court/indoor': 25, 'baggage_claim': 26, 'bakery/shop': 27, 'balcony/exterior': 28, 'balcony/interior': 29, 'ball_pit': 30, 'ballroom': 31, 'bamboo_forest': 32, 'banquet_hall': 33, 'bar': 34, 'barn': 35, 'barndoor': 36, 'baseball_field': 37, 'basement': 38, 'basilica': 39, 'basketball_court/outdoor': 40, 'bathroom': 41, 'batters_box': 42, 'bayou': 43, 'bazaar/indoor': 44, 'bazaar/outdoor': 45, 'beach': 46, 'beauty_salon': 47, 'bedroom': 48, 'berth': 49, 'biology_laboratory': 50, 'bistro/indoor': 51, 'boardwalk': 52, 'boat_deck': 53, 'boathouse': 54, 'bookstore': 55, 'booth/indoor': 56, 'botanical_garden': 57, 'bow_window/indoor': 58, 'bow_window/outdoor': 59, 'bowling_alley': 60, 'boxing_ring': 61, 'brewery/indoor': 62, 'bridge': 63, 'building_facade': 64, 'bullring': 65, 'burial_chamber': 66, 'bus_interior': 67, 'butchers_shop': 68, 'butte': 69, 'cabin/outdoor': 70, 'cafeteria': 71, 'campsite': 72, 'campus': 73, 'canal/natural': 74, 'canal/urban': 75, 'candy_store': 76, 'canyon': 77, 'car_interior/backseat': 78, 'car_interior/frontseat': 79, 'carrousel': 80, 'casino/indoor': 81, 'castle': 82, 'catacomb': 83, 'cathedral/indoor': 84, 'cathedral/outdoor': 85, 'cavern/indoor': 86, 'cemetery': 87, 'chalet': 88, 'cheese_factory': 89, 'chemistry_lab': 90, 'chicken_coop/indoor': 91, 'chicken_coop/outdoor': 92, 'childs_room': 93, 'church/indoor': 94, 'church/outdoor': 95, 'classroom': 96, 'clean_room': 97, 'cliff': 98, 'cloister/indoor': 99, 'closet': 100, 'clothing_store': 101, 'coast': 102, 'cockpit': 103, 'coffee_shop': 104, 'computer_room': 105, 'conference_center': 106, 'conference_room': 107, 'construction_site': 108, 'control_room': 109, 'control_tower/outdoor': 110, 'corn_field': 111, 'corral': 112, 'corridor': 113, 'cottage_garden': 114, 'courthouse': 115, 'courtroom': 116, 'courtyard': 117, 'covered_bridge/exterior': 118, 'creek': 119, 'crevasse': 120, 'crosswalk': 121, 'cubicle/office': 122, 'dam': 123, 'delicatessen': 124, 'dentists_office': 125, 'desert/sand': 126, 'desert/vegetation': 127, 'diner/indoor': 128, 'diner/outdoor': 129, 'dinette/home': 130, 'dinette/vehicle': 131, 'dining_car': 132, 'dining_room': 133, 'discotheque': 134, 'dock': 135, 'doorway/outdoor': 136, 'dorm_room': 137, 'driveway': 138, 'driving_range/outdoor': 139, 'drugstore': 140, 'electrical_substation': 141, 'elevator/door': 142, 'elevator/interior': 143, 'elevator_shaft': 144, 'engine_room': 145, 'escalator/indoor': 146, 'excavation': 147, 'factory/indoor': 148, 'fairway': 149, 'fastfood_restaurant': 150, 'field/cultivated': 151, 'field/wild': 152, 'fire_escape': 153, 'fire_station': 154, 'firing_range/indoor': 155, 'fishpond': 156, 'florist_shop/indoor': 157, 'food_court': 158, 'forest/broadleaf': 159, 'forest/needleleaf': 160, 'forest_path': 161, 'forest_road': 162, 'formal_garden': 163, 'fountain': 164, 'galley': 165, 'game_room': 166, 'garage/indoor': 167, 'garbage_dump': 168, 'gas_station': 169, 'gazebo/exterior': 170, 'general_store/indoor': 171, 'general_store/outdoor': 172, 'gift_shop': 173, 'golf_course': 174, 'greenhouse/indoor': 175, 'greenhouse/outdoor': 176, 'gymnasium/indoor': 177, 'hangar/indoor': 178, 'hangar/outdoor': 179, 'harbor': 180, 'hayfield': 181, 'heliport': 182, 'herb_garden': 183, 'highway': 184, 'hill': 185, 'home_office': 186, 'hospital': 187, 'hospital_room': 188, 'hot_spring': 189, 'hot_tub/outdoor': 190, 'hotel/outdoor': 191, 'hotel_room': 192, 'house': 193, 'hunting_lodge/outdoor': 194, 'ice_cream_parlor': 195, 'ice_floe': 196, 'ice_shelf': 197, 'ice_skating_rink/indoor': 198, 'ice_skating_rink/outdoor': 199, 'iceberg': 200, 'igloo': 201, 'industrial_area': 202, 'inn/outdoor': 203, 'islet': 204, 'jacuzzi/indoor': 205, 'jail/indoor': 206, 'jail_cell': 207, 'jewelry_shop': 208, 'kasbah': 209, 'kennel/indoor': 210, 'kennel/outdoor': 211, 'kindergarden_classroom': 212, 'kitchen': 213, 'kitchenette': 214, 'labyrinth/outdoor': 215, 'lake/natural': 216, 'landfill': 217, 'landing_deck': 218, 'laundromat': 219, 'lecture_room': 220, 'library/indoor': 221, 'library/outdoor': 222, 'lido_deck/outdoor': 223, 'lift_bridge': 224, 'lighthouse': 225, 'limousine_interior': 226, 'living_room': 227, 'lobby': 228, 'lock_chamber': 229, 'locker_room': 230, 'mansion': 231, 'manufactured_home': 232, 'market/indoor': 233, 'market/outdoor': 234, 'marsh': 235, 'martial_arts_gym': 236, 'mausoleum': 237, 'medina': 238, 'moat/water': 239, 'monastery/outdoor': 240, 'mosque/indoor': 241, 'mosque/outdoor': 242, 'motel': 243, 'mountain': 244, 'mountain_snowy': 245, 'movie_theater/indoor': 246, 'museum/indoor': 247, 'music_store': 248, 'music_studio': 249, 'nuclear_power_plant/outdoor': 250, 'nursery': 251, 'oast_house': 252, 'observatory/outdoor': 253, 'ocean': 254, 'office': 255, 'office_building': 256, 'oil_refinery/outdoor': 257, 'oilrig': 258, 'operating_room': 259, 'orchard': 260, 'outhouse/outdoor': 261, 'pagoda': 262, 'palace': 263, 'pantry': 264, 'park': 265, 'parking_garage/indoor': 266, 'parking_garage/outdoor': 267, 'parking_lot': 268, 'parlor': 269, 'pasture': 270, 'patio': 271, 'pavilion': 272, 'pharmacy': 273, 'phone_booth': 274, 'physics_laboratory': 275, 'picnic_area': 276, 'pilothouse/indoor': 277, 'planetarium/outdoor': 278, 'playground': 279, 'playroom': 280, 'plaza': 281, 'podium/indoor': 282, 'podium/outdoor': 283, 'pond': 284, 'poolroom/establishment': 285, 'poolroom/home': 286, 'power_plant/outdoor': 287, 'promenade_deck': 288, 'pub/indoor': 289, 'pulpit': 290, 'putting_green': 291, 'racecourse': 292, 'raceway': 293, 'raft': 294, 'railroad_track': 295, 'rainforest': 296, 'reception': 297, 'recreation_room': 298, 'residential_neighborhood': 299, 'restaurant': 300, 'restaurant_kitchen': 301, 'restaurant_patio': 302, 'rice_paddy': 303, 'riding_arena': 304, 'river': 305, 'rock_arch': 306, 'rope_bridge': 307, 'ruin': 308, 'runway': 309, 'sandbar': 310, 'sandbox': 311, 'sauna': 312, 'schoolhouse': 313, 'sea_cliff': 314, 'server_room': 315, 'shed': 316, 'shoe_shop': 317, 'shopfront': 318, 'shopping_mall/indoor': 319, 'shower': 320, 'skatepark': 321, 'ski_lodge': 322, 'ski_resort': 323, 'ski_slope': 324, 'sky': 325, 'skyscraper': 326, 'slum': 327, 'snowfield': 328, 'squash_court': 329, 'stable': 330, 'stadium/baseball': 331, 'stadium/football': 332, 'stage/indoor': 333, 'staircase': 334, 'street': 335, 'subway_interior': 336, 'subway_station/platform': 337, 'supermarket': 338, 'sushi_bar': 339, 'swamp': 340, 'swimming_pool/indoor': 341, 'swimming_pool/outdoor': 342, 'synagogue/indoor': 343, 'synagogue/outdoor': 344, 'television_studio': 345, 'temple/east_asia': 346, 'temple/south_asia': 347, 'tennis_court/indoor': 348, 'tennis_court/outdoor': 349, 'tent/outdoor': 350, 'theater/indoor_procenium': 351, 'theater/indoor_seats': 352, 'thriftshop': 353, 'throne_room': 354, 'ticket_booth': 355, 'toll_plaza': 356, 'topiary_garden': 357, 'tower': 358, 'toyshop': 359, 'track/outdoor': 360, 'train_railway': 361, 'train_station/platform': 362, 'tree_farm': 363, 'tree_house': 364, 'trench': 365, 'underwater/coral_reef': 366, 'utility_room': 367, 'valley': 368, 'van_interior': 369, 'vegetable_garden': 370, 'veranda': 371, 'veterinarians_office': 372, 'viaduct': 373, 'videostore': 374, 'village': 375, 'vineyard': 376, 'volcano': 377, 'volleyball_court/indoor': 378, 'volleyball_court/outdoor': 379, 'waiting_room': 380, 'warehouse/indoor': 381, 'water_tower': 382, 'waterfall/block': 383, 'waterfall/fan': 384, 'waterfall/plunge': 385, 'watering_hole': 386, 'wave': 387, 'wet_bar': 388, 'wheat_field': 389, 'wind_farm': 390, 'windmill': 391, 'wine_cellar/barrel_storage': 392, 'wine_cellar/bottle_storage': 393, 'wrestling_ring/indoor': 394, 'yard': 395, 'youth_hostel': 396}\n",
      "FGVC-Aircraft classes: {'707-320': 0, '727-200': 1, '737-200': 2, '737-300': 3, '737-400': 4, '737-500': 5, '737-600': 6, '737-700': 7, '737-800': 8, '737-900': 9, '747-100': 10, '747-200': 11, '747-300': 12, '747-400': 13, '757-200': 14, '757-300': 15, '767-200': 16, '767-300': 17, '767-400': 18, '777-200': 19, '777-300': 20, 'A300B4': 21, 'A310': 22, 'A318': 23, 'A319': 24, 'A320': 25, 'A321': 26, 'A330-200': 27, 'A330-300': 28, 'A340-200': 29, 'A340-300': 30, 'A340-500': 31, 'A340-600': 32, 'A380': 33, 'ATR-42': 34, 'ATR-72': 35, 'An-12': 36, 'BAE 146-200': 37, 'BAE 146-300': 38, 'BAE-125': 39, 'Beechcraft 1900': 40, 'Boeing 717': 41, 'C-130': 42, 'C-47': 43, 'CRJ-200': 44, 'CRJ-700': 45, 'CRJ-900': 46, 'Cessna 172': 47, 'Cessna 208': 48, 'Cessna 525': 49, 'Cessna 560': 50, 'Challenger 600': 51, 'DC-10': 52, 'DC-3': 53, 'DC-6': 54, 'DC-8': 55, 'DC-9-30': 56, 'DH-82': 57, 'DHC-1': 58, 'DHC-6': 59, 'DHC-8-100': 60, 'DHC-8-300': 61, 'DR-400': 62, 'Dornier 328': 63, 'E-170': 64, 'E-190': 65, 'E-195': 66, 'EMB-120': 67, 'ERJ 135': 68, 'ERJ 145': 69, 'Embraer Legacy 600': 70, 'Eurofighter Typhoon': 71, 'F-16A/B': 72, 'F/A-18': 73, 'Falcon 2000': 74, 'Falcon 900': 75, 'Fokker 100': 76, 'Fokker 50': 77, 'Fokker 70': 78, 'Global Express': 79, 'Gulfstream IV': 80, 'Gulfstream V': 81, 'Hawk T1': 82, 'Il-76': 83, 'L-1011': 84, 'MD-11': 85, 'MD-80': 86, 'MD-87': 87, 'MD-90': 88, 'Metroliner': 89, 'Model B200': 90, 'PA-28': 91, 'SR-20': 92, 'Saab 2000': 93, 'Saab 340': 94, 'Spitfire': 95, 'Tornado': 96, 'Tu-134': 97, 'Tu-154': 98, 'Yak-42': 99}\n",
      "Oxford-IIIT Pet classes: {'Abyssinian': 0, 'American Bulldog': 1, 'American Pit Bull Terrier': 2, 'Basset Hound': 3, 'Beagle': 4, 'Bengal': 5, 'Birman': 6, 'Bombay': 7, 'Boxer': 8, 'British Shorthair': 9, 'Chihuahua': 10, 'Egyptian Mau': 11, 'English Cocker Spaniel': 12, 'English Setter': 13, 'German Shorthaired': 14, 'Great Pyrenees': 15, 'Havanese': 16, 'Japanese Chin': 17, 'Keeshond': 18, 'Leonberger': 19, 'Maine Coon': 20, 'Miniature Pinscher': 21, 'Newfoundland': 22, 'Persian': 23, 'Pomeranian': 24, 'Pug': 25, 'Ragdoll': 26, 'Russian Blue': 27, 'Saint Bernard': 28, 'Samoyed': 29, 'Scottish Terrier': 30, 'Shiba Inu': 31, 'Siamese': 32, 'Sphynx': 33, 'Staffordshire Bull Terrier': 34, 'Wheaten Terrier': 35, 'Yorkshire Terrier': 36}\n",
      "EuroSAT classes: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n"
     ]
    }
   ],
   "source": [
    "cifar10_val_loader = create_zeroshot_dataloader(\n",
    "    \"cifar10\", \"/BS/dduka/work/projects/old_projects/TempNet/Bimodal_CL/cifar10\", image_size=224, train=False\n",
    ")\n",
    "\n",
    "cifar100_val_loader = create_zeroshot_dataloader(\n",
    "    \"cifar100\", \"/BS/dduka/work/projects/old_projects/TempNet/Bimodal_CL/cifar100\", image_size=224, train=False\n",
    ")\n",
    "\n",
    "mnist_val_loader = create_zeroshot_dataloader(\n",
    "    \"mnist\", \"/BS/dduka/work/projects/old_projects/TempNet/Bimodal_CL/mnist\", image_size=224, train=False\n",
    ")\n",
    "\n",
    "sun397_val_loader = create_zeroshot_dataloader(\n",
    "    \"sun397\", \"/BS/databases03\", image_size=224, train=False\n",
    ")\n",
    "\n",
    "fgvc_aircraft_val_loader = create_zeroshot_dataloader(\n",
    "    \"fgvc-aircraft\", \"/BS/databases07/fgvc-aircraft\", image_size=224, train=False\n",
    ")\n",
    "\n",
    "oxford_pets_val_loader = create_zeroshot_dataloader(\n",
    "    \"oxford-pets\", \"/BS/databases05/\", image_size=224, train=False\n",
    ")\n",
    "\n",
    "flowers102_val_loader = create_zeroshot_dataloader(\n",
    "    \"flowers102\", \n",
    "    \"\",\n",
    "    image_size=224,\n",
    "    train=False\n",
    ")   \n",
    "\n",
    "eurosat_val_loader = create_zeroshot_dataloader(\n",
    "    \"eurosat\",\n",
    "    \"\",\n",
    "    image_size=224,\n",
    "    train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03de3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [(\"cifar10\", cifar10_val_loader),\n",
    "           (\"cifar100\", cifar100_val_loader),\n",
    "           (\"mnist\", mnist_val_loader),\n",
    "           (\"sun397\", sun397_val_loader),\n",
    "           (\"fgvc-aircraft\", fgvc_aircraft_val_loader),\n",
    "           (\"oxford-pets\", oxford_pets_val_loader),\n",
    "           (\"flowers102\", flowers102_val_loader),\n",
    "           (\"eurosat\", eurosat_val_loader)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb28eff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset: cifar10, number of samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2593014/1001797372.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_tau_0.01_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for cifar10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.40it/s]\n",
      "/tmp/ipykernel_2593014/1001797372.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_tau_0.01_lr_8e-4 on dataset cifar10: {'zeroshot_top1': 0.5473, 'zeroshot_top3': 0.8195, 'zeroshot_top5': 0.9137, 'zeroshot_top10': 1.0}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_cos_0.01_0.05_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for cifar10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_cos_0.01_0.05_lr_8e-4 on dataset cifar10: {'zeroshot_top1': 0.524, 'zeroshot_top3': 0.8147, 'zeroshot_top5': 0.9194, 'zeroshot_top10': 1.0}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for cifar10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented on dataset cifar10: {'zeroshot_top1': 0.6657, 'zeroshot_top3': 0.915, 'zeroshot_top5': 0.9674, 'zeroshot_top10': 1.0}\n",
      "Validation dataset: cifar100, number of samples: 10000\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_tau_0.01_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for cifar100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_tau_0.01_lr_8e-4 on dataset cifar100: {'zeroshot_top1': 0.2658, 'zeroshot_top3': 0.4348, 'zeroshot_top5': 0.5277, 'zeroshot_top10': 0.6412}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_cos_0.01_0.05_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for cifar100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_cos_0.01_0.05_lr_8e-4 on dataset cifar100: {'zeroshot_top1': 0.3032, 'zeroshot_top3': 0.4805, 'zeroshot_top5': 0.5586, 'zeroshot_top10': 0.6681}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for cifar100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented on dataset cifar100: {'zeroshot_top1': 0.3937, 'zeroshot_top3': 0.5999, 'zeroshot_top5': 0.6801, 'zeroshot_top10': 0.786}\n",
      "Validation dataset: mnist, number of samples: 10000\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_tau_0.01_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for mnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_tau_0.01_lr_8e-4 on dataset mnist: {'zeroshot_top1': 0.1393, 'zeroshot_top3': 0.3501, 'zeroshot_top5': 0.5798, 'zeroshot_top10': 1.0}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_cos_0.01_0.05_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for mnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_cos_0.01_0.05_lr_8e-4 on dataset mnist: {'zeroshot_top1': 0.0984, 'zeroshot_top3': 0.3192, 'zeroshot_top5': 0.5563, 'zeroshot_top10': 1.0}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for mnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 40/40 [00:05<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented on dataset mnist: {'zeroshot_top1': 0.1068, 'zeroshot_top3': 0.3474, 'zeroshot_top5': 0.5306, 'zeroshot_top10': 1.0}\n",
      "Validation dataset: sun397, number of samples: 108754\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_tau_0.01_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for sun397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 425/425 [06:39<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_tau_0.01_lr_8e-4 on dataset sun397: {'zeroshot_top1': 0.4182558802434853, 'zeroshot_top3': 0.6504220534417124, 'zeroshot_top5': 0.7376924067160748, 'zeroshot_top10': 0.8293947808816228}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_cos_0.01_0.05_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for sun397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 425/425 [06:33<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_cos_0.01_0.05_lr_8e-4 on dataset sun397: {'zeroshot_top1': 0.4470180407157438, 'zeroshot_top3': 0.6702374165547934, 'zeroshot_top5': 0.7530573588097909, 'zeroshot_top10': 0.8377622892031558}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for sun397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 425/425 [06:32<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented on dataset sun397: {'zeroshot_top1': 0.445942218217261, 'zeroshot_top3': 0.6813174687827575, 'zeroshot_top5': 0.7662522757783622, 'zeroshot_top10': 0.8537249204626957}\n",
      "Validation dataset: fgvc-aircraft, number of samples: 3333\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_tau_0.01_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for fgvc-aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 14/14 [00:12<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_tau_0.01_lr_8e-4 on dataset fgvc-aircraft: {'zeroshot_top1': 0.0111011101110111, 'zeroshot_top3': 0.0351035103510351, 'zeroshot_top5': 0.056405640564056406, 'zeroshot_top10': 0.12091209120912091}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_cos_0.01_0.05_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for fgvc-aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 14/14 [00:06<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_clip_cos_0.01_0.05_lr_8e-4 on dataset fgvc-aircraft: {'zeroshot_top1': 0.0144014401440144, 'zeroshot_top3': 0.0429042904290429, 'zeroshot_top5': 0.06900690069006901, 'zeroshot_top10': 0.13081308130813082}\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for fgvc-aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating zeroshot transfer: 100%|██████████| 14/14 [00:07<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model r_scheduled_clip_0.01_0.04_lr_2e-4_quad_crossmodal_and_unimodal_augmented on dataset fgvc-aircraft: {'zeroshot_top1': 0.012601260126012601, 'zeroshot_top3': 0.0408040804080408, 'zeroshot_top5': 0.06930693069306931, 'zeroshot_top10': 0.13021302130213022}\n",
      "Validation dataset: oxford-pets, number of samples: 3669\n",
      "Load checkpoint from /BS/dduka/work/training_metadata/bimodal_cl/dhimitrios/r_clip_tau_0.01_lr_8e-4/checkpoint_best.pth\n",
      "Keys in checkpoint model: dict_keys(['model', 'optimizer', 'lr_scheduler', 'args', 'epoch'])\n",
      "===> Loading zeroshot transfer config for oxford-pets\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'zeroshot_transfer/oxford-pets_classes.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad checkpoint from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m checkpoint_path)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeys in checkpoint model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mzeroshot_transfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrn50_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m row \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: checkpoint_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset_name,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresults\n\u001b[1;32m     25\u001b[0m }\n\u001b[1;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, pd\u001b[38;5;241m.\u001b[39mDataFrame([row])], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/BS/dduka/work/micromamba/envs/bimodal_cl/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 10\u001b[0m, in \u001b[0;36mzeroshot_transfer\u001b[0;34m(model, data_loader, dataset_name, tokenizer, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===> Loading zeroshot transfer config for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzeroshot_transfer/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_classes.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     11\u001b[0m     classes, templates \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplates\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m text_embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/BS/dduka/work/micromamba/envs/bimodal_cl/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'zeroshot_transfer/oxford-pets_classes.py'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"model\", \"dataset\", \"zeroshot_top1\", \"zeroshot_top3\", \"zeroshot_top5\", \"zeroshot_top10\"])\n",
    "\n",
    "for dataset_name, val_loader in loaders:\n",
    "    print(f\"Validation dataset: {dataset_name}, number of samples: {val_loader.num_samples}\")\n",
    "    \n",
    "    for checkpoint_path in rn50_checkpoint_paths:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "        state_dict = checkpoint[\"model\"]\n",
    "        rn50_model.load_state_dict(state_dict, strict=False)\n",
    "        print(\"Load checkpoint from %s\" % checkpoint_path)\n",
    "        print(f\"Keys in checkpoint model: {checkpoint.keys()}\")\n",
    "        \n",
    "        results = zeroshot_transfer(\n",
    "            rn50_model,\n",
    "            val_loader,\n",
    "            dataset_name,\n",
    "            tokenizer,\n",
    "            device=\"cuda\",\n",
    "        )\n",
    "\n",
    "        row = {\n",
    "            \"model\": checkpoint_path.split(\"/\")[-2],\n",
    "            \"dataset\": dataset_name,\n",
    "            **results\n",
    "        }\n",
    "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "        print(f\"Results for model {checkpoint_path.split('/')[-2]} on dataset {dataset_name}: {results}\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c139632",
   "metadata": {},
   "source": [
    "# ViT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebf6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit50_model = CLIP(\n",
    "    **vit_args\n",
    ")\n",
    "print(vit50_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc90c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/BS/scratch/inf0/user/dduka\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3e2766",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FER2013.__init__() got an unexpected keyword argument 'download'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFER2013\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPublicTest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: FER2013.__init__() got an unexpected keyword argument 'download'"
     ]
    }
   ],
   "source": [
    "datasets.FER2013(\n",
    "    root=data_folder, split=\"PublicTest\", download=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bimodal_cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
